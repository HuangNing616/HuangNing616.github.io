<!DOCTYPE html>



<html lang="zh-CN">

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">
  <meta name="google-site-verification" content="d1AGlulK-YE5DyygkFpJxEEeJpwC8OAk07ZzYE6ewJM">
  <meta name="baidu-site-verification" content="uMYiXVMIsE">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.loli.net/css?family=Roboto Slab:300,300italic,400,400italic,700,700italic|sans-serif:300,300italic,400,400italic,700,700italic|Times New Roman:300,300italic,400,400italic,700,700italic|PT Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">
<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.css">


<script id="hexo-configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    hostname: new URL('http://yoursite.com').hostname,
    root: '/',
    scheme: 'Pisces',
    version: '7.6.0',
    exturl: false,
    sidebar: {"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},
    copycode: {"enable":false,"show_result":false,"style":null},
    back2top: {"enable":true,"sidebar":false,"scrollpercent":false},
    bookmark: {"enable":false,"color":"#222","save":"auto"},
    fancybox: true,
    mediumzoom: false,
    lazyload: false,
    pangu: false,
    comments: {"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},
    algolia: {
      appID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    },
    localsearch: {"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},
    path: '',
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}}
  };
</script>

  <meta name="description" content="Spark有两个机器学习包，分别是基于RDD的spark.mliib以及基于DataFrame的spark.mllib，从Spark 2.0开始spark.mllib开始进入维护模式，目前仍然支持RDD的API但之后不会添加新的特性，但是在Spark3.0的时候RDD的API将会被移除。为了达到与RDD的API平等的地位，在Spark 2.x中DataFrame的API会一直添加新的特性，在Spa">
<meta property="og:type" content="article">
<meta property="og:title" content="SparkML学习笔记">
<meta property="og:url" content="http://yoursite.com/2020/09/05/SparkML%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/index.html">
<meta property="og:site_name" content="黄宁の博客">
<meta property="og:description" content="Spark有两个机器学习包，分别是基于RDD的spark.mliib以及基于DataFrame的spark.mllib，从Spark 2.0开始spark.mllib开始进入维护模式，目前仍然支持RDD的API但之后不会添加新的特性，但是在Spark3.0的时候RDD的API将会被移除。为了达到与RDD的API平等的地位，在Spark 2.x中DataFrame的API会一直添加新的特性，在Spa">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2020-09-05T04:03:43.000Z">
<meta property="article:modified_time" content="2020-09-19T08:21:44.482Z">
<meta property="article:author" content="黄宁">
<meta property="article:tag" content="｜统计学|机器学习|python|">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://yoursite.com/2020/09/05/SparkML%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome: false,
    isPost: true
  };
</script>

  <title>SparkML学习笔记 | 黄宁の博客</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>


</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>
	<a href="https://github.com/HuangNing616" target="_blank" rel="noopener" class="github-corner" aria-label="View source on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#151513; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a><style>.github-corner:hover .octo-arm{animation:octocat-wave 560ms ease-in-out}@keyframes octocat-wave{0%,100%{transform:rotate(0)}20%,60%{transform:rotate(-25deg)}40%,80%{transform:rotate(10deg)}}@media (max-width:500px){.github-corner:hover .octo-arm{animation:none}.github-corner .octo-arm{animation:octocat-wave 560ms ease-in-out}}</style>
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-meta">

    <div>
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">黄宁の博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
        <p class="site-subtitle">算法攻城狮</p>
  </div>

  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>
</div>


<nav class="site-nav">
  
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-fw fa-th"></i>分类</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-fw fa-user"></i>关于</a>

  </li>
  </ul>

</nav>
</div>
    </header>



    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content">
            

  <div class="posts-expand">
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block " lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2020/09/05/SparkML%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/%E4%BA%91%E5%8D%97%E5%B1%B1%E9%97%B4%E8%87%AA%E6%8B%8D.jpg">
      <meta itemprop="name" content="黄宁">
      <meta itemprop="description" content="务实敢为 追求极致">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="黄宁の博客">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          SparkML学习笔记
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2020-09-05 12:03:43" itemprop="dateCreated datePublished" datetime="2020-09-05T12:03:43+08:00">2020-09-05</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                <span class="post-meta-item-text">更新于</span>
                <time title="修改时间：2020-09-19 16:21:44" itemprop="dateModified" datetime="2020-09-19T16:21:44+08:00">2020-09-19</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/" itemprop="url" rel="index">
                    <span itemprop="name">计算机</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/" itemprop="url" rel="index">
                    <span itemprop="name">分布式计算</span>
                  </a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA/%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%A1%E7%AE%97/SparkML%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" itemprop="url" rel="index">
                    <span itemprop="name">SparkML学习笔记</span>
                  </a>
                </span>
            </span>

          
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span><br>
            <span class="post-meta-item" title="本文字数">
              <span class="post-meta-item-icon">
                <i class="fa fa-file-word-o"></i>
              </span>
                <span class="post-meta-item-text">本文字数：</span>
              <span>6.3k</span>
            </span>
            <span class="post-meta-item" title="阅读时长">
              <span class="post-meta-item-icon">
                <i class="fa fa-clock-o"></i>
              </span>
                <span class="post-meta-item-text">阅读时长 &asymp;</span>
              <span>6 分钟</span>
            </span>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>Spark有两个机器学习包，分别是基于RDD的<code>spark.mliib</code>以及基于DataFrame的<code>spark.mllib</code>，从Spark 2.0开始<code>spark.mllib</code>开始进入维护模式，目前仍然支持RDD的API但之后不会添加新的特性，但是在Spark3.0的时候RDD的API将会被移除。为了达到与RDD的API平等的地位，在Spark 2.x中DataFrame的API会一直添加新的特性，在Spark2.3的时候大致实现了该目标。</p>
<a id="more"></a>
<h1 id="基本统计量"><a href="#基本统计量" class="headerlink" title="基本统计量"></a>基本统计量</h1><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 1. dense向量是普通的double数组，而sparse向量是由两个并列的数组indices和values组成</span></span><br><span class="line"><span class="comment"> * 2. 计算Person相关系数的变量必须要满足连续性，接近单峰分布以及每对观测指相互独立</span></span><br><span class="line"><span class="comment"> * 3. 卡方检验要满足特征和标签是类别变量</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">BasicStatistics</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().appName(<span class="string">"BasicStatistics"</span>).master(<span class="string">"local"</span>).getOrCreate()</span><br><span class="line">    spark.sparkContext.setLogLevel(<span class="string">"Error"</span>)</span><br><span class="line">    <span class="keyword">import</span> spark.implicits._</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> data: <span class="type">Seq</span>[linalg.<span class="type">Vector</span>] = <span class="type">Seq</span>(</span><br><span class="line">      <span class="type">Vectors</span>.sparse(<span class="number">4</span>, <span class="type">Seq</span>((<span class="number">0</span>, <span class="number">1.0</span>), (<span class="number">3</span>, <span class="number">-2.0</span>))),</span><br><span class="line">      <span class="type">Vectors</span>.dense(<span class="number">4.0</span>, <span class="number">5.0</span>, <span class="number">0.0</span>, <span class="number">3.0</span>),</span><br><span class="line">      <span class="type">Vectors</span>.dense(<span class="number">6.0</span>, <span class="number">7.0</span>, <span class="number">0.0</span>, <span class="number">8.0</span>),</span><br><span class="line">      <span class="type">Vectors</span>.sparse(<span class="number">4</span>, <span class="type">Seq</span>((<span class="number">0</span>, <span class="number">9.0</span>), (<span class="number">3</span>, <span class="number">1.0</span>)))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 两种相关系数的计算方法</span></span><br><span class="line">    <span class="keyword">val</span> df: <span class="type">DataFrame</span> = data.map(<span class="type">Tuple1</span>.apply).toDF(<span class="string">"features"</span>)</span><br><span class="line">    <span class="keyword">val</span> <span class="type">Row</span>(coeff1: <span class="type">Matrix</span>): <span class="type">Row</span> = <span class="type">Correlation</span>.corr(df, <span class="string">"features"</span>).head</span><br><span class="line">    println(<span class="string">s"Pearson correlation matrix:\n <span class="subst">$coeff1</span>, <span class="subst">$&#123;coeff1.getClass&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> <span class="type">Row</span>(coeff2: <span class="type">Matrix</span>): <span class="type">Row</span> = <span class="type">Correlation</span>.corr(df, <span class="string">"features"</span>, <span class="string">"spearman"</span>).head</span><br><span class="line">    println(<span class="string">s"Spearman correlation matrix:\n <span class="subst">$coeff2</span>"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Pearson’s Chi-squared ( χ2) tests for independence</span></span><br><span class="line">    <span class="keyword">val</span> data2: <span class="type">Seq</span>[(<span class="type">Double</span>, linalg.<span class="type">Vector</span>)] = <span class="type">Seq</span>(</span><br><span class="line">      (<span class="number">0.0</span>, <span class="type">Vectors</span>.dense(<span class="number">0.5</span>, <span class="number">10.0</span>)),</span><br><span class="line">      (<span class="number">0.0</span>, <span class="type">Vectors</span>.dense(<span class="number">1.5</span>, <span class="number">20.0</span>)),</span><br><span class="line">      (<span class="number">1.0</span>, <span class="type">Vectors</span>.dense(<span class="number">1.5</span>, <span class="number">30.0</span>)),</span><br><span class="line">      (<span class="number">0.0</span>, <span class="type">Vectors</span>.dense(<span class="number">3.5</span>, <span class="number">30.0</span>)),</span><br><span class="line">      (<span class="number">0.0</span>, <span class="type">Vectors</span>.dense(<span class="number">3.5</span>, <span class="number">40.0</span>)),</span><br><span class="line">      (<span class="number">1.0</span>, <span class="type">Vectors</span>.dense(<span class="number">3.5</span>, <span class="number">40.0</span>))</span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> df2: <span class="type">DataFrame</span> = data2.toDF(<span class="string">"label"</span>, <span class="string">"features"</span>)</span><br><span class="line">    <span class="keyword">val</span> chi: <span class="type">Row</span> = <span class="type">ChiSquareTest</span>.test(df2, <span class="string">"features"</span>, <span class="string">"label"</span>).head</span><br><span class="line"></span><br><span class="line">    println(<span class="string">s"pValues = <span class="subst">$&#123;chi.getAs[Vector](0)&#125;</span>"</span>)</span><br><span class="line">    println(<span class="string">s"degreesOfFreedom <span class="subst">$&#123;chi.getSeq[Int](1).mkString("[", ",", "]")&#125;</span>"</span>)</span><br><span class="line">    println(<span class="string">s"statistics <span class="subst">$&#123;chi.getAs[Vector](2)&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="基本组件"><a href="#基本组件" class="headerlink" title="基本组件"></a>基本组件</h1><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 1. Transformer</span></span><br><span class="line"><span class="comment"> *    Transformer是抽象类，它包含feature transformer和learned model</span></span><br><span class="line"><span class="comment"> *    1）feature transformer的原理是将读入的列map成新列feature vectors，然后将其追加到DataFrame</span></span><br><span class="line"><span class="comment"> *    2) learning model的原理是读入feature vectors列并预测标签，然后将其追加到DataFrame</span></span><br><span class="line"><span class="comment"> * 2. Estimator</span></span><br><span class="line"><span class="comment"> *    Estimator是可以拟合数据的各类算法的抽象类，它实现了.fit()，即接收DataFrame返回Model，这里的Model是transformer</span></span><br><span class="line"><span class="comment"> * 3. Parameters</span></span><br><span class="line"><span class="comment"> *    1) 有两种方法将参数传入算法</span></span><br><span class="line"><span class="comment"> *    法1. 针对算法的实例设定参数，比如针对LogisticRegression的实例lr设定参数lr.setMaxIter(10)，使得lr.fit()的时候迭代了10次</span></span><br><span class="line"><span class="comment"> *    法2. 将ParamMap传入fit()或者transform(). ParamMap中的任意参数都会覆盖原本设定的参数</span></span><br><span class="line"><span class="comment"> *    2) 参数只属于Estimators以及Transformers的实例，比如有两个LogisticRegression实例lr1和lr2，那么可以将参数构建成ParamMap(lr1.maxIter -&gt; 10, lr2.maxIter -&gt; 20).</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">TransEstAndParam</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> =&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().appName(<span class="string">"TransFormerAndEstimator"</span>).master(<span class="string">"local"</span>).getOrCreate()</span><br><span class="line">    spark.sparkContext.setLogLevel(<span class="string">"Error"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 由tuple构成的Seq来作为训练集</span></span><br><span class="line">    <span class="keyword">val</span> training: <span class="type">DataFrame</span> = spark.createDataFrame(<span class="type">Seq</span>(</span><br><span class="line">      (<span class="number">1.0</span>, <span class="type">Vectors</span>.dense(<span class="number">0.0</span>, <span class="number">1.1</span>, <span class="number">0.1</span>)),</span><br><span class="line">      (<span class="number">0.0</span>, <span class="type">Vectors</span>.dense(<span class="number">2.0</span>, <span class="number">1.0</span>, <span class="number">-1.0</span>)),</span><br><span class="line">      (<span class="number">0.0</span>, <span class="type">Vectors</span>.dense(<span class="number">2.0</span>, <span class="number">1.3</span>, <span class="number">1.0</span>)),</span><br><span class="line">      (<span class="number">1.0</span>, <span class="type">Vectors</span>.dense(<span class="number">0.0</span>, <span class="number">1.2</span>, <span class="number">-0.5</span>))</span><br><span class="line">    )).toDF(<span class="string">"label"</span>, <span class="string">"features"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 创建一个LogisticRegression实例（Estimator）</span></span><br><span class="line">    <span class="keyword">val</span> lr: <span class="type">LogisticRegression</span> = <span class="keyword">new</span> <span class="type">LogisticRegression</span>()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 通过explainParams打印参数文档</span></span><br><span class="line">    println(<span class="string">s"LogisticRegression parameters:\n <span class="subst">$&#123;lr.explainParams()&#125;</span>\n"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 通过传递参数的法1来配置参数</span></span><br><span class="line">    lr.setMaxIter(<span class="number">10</span>)</span><br><span class="line">      .setRegParam(<span class="number">0.01</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 使用之前设定的参数来学习模型(Transformer)</span></span><br><span class="line">    <span class="keyword">val</span> lr_clf: <span class="type">LogisticRegressionModel</span> = lr.fit(training)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 通过.parent.extractParamMap查看fit期间的参数，打印的参数是name，value，其中names就是LogisticRegression实例的ID</span></span><br><span class="line">    println(<span class="string">s"Model 1 was fit using parameters: <span class="subst">$&#123;lr_clf.parent.extractParamMap&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 通过传递参数的法2来配置参数，可以指定一个参数，也可以同时指定多个参数，其中重复配置的参数会覆盖以前的参数</span></span><br><span class="line">    <span class="keyword">val</span> paramMap: <span class="type">ParamMap</span> = <span class="type">ParamMap</span>(lr.maxIter -&gt; <span class="number">20</span>)</span><br><span class="line">      .put(lr.maxIter, <span class="number">30</span>)</span><br><span class="line">      .put(lr.regParam -&gt; <span class="number">0.1</span>, lr.threshold -&gt; <span class="number">0.55</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 修改输出概率列的列名(ParamMaps可以相互结合)</span></span><br><span class="line">    <span class="keyword">val</span> paramMap2: <span class="type">ParamMap</span> = <span class="type">ParamMap</span>(lr.probabilityCol -&gt; <span class="string">"myProbability"</span>)</span><br><span class="line">    <span class="keyword">val</span> paramMapCombined: <span class="type">ParamMap</span> = paramMap ++ paramMap2</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将paramMapCombined传入fit中</span></span><br><span class="line">    <span class="keyword">val</span> model2: <span class="type">LogisticRegressionModel</span> = lr.fit(training, paramMapCombined)</span><br><span class="line">    println(<span class="string">s"Model 2 was fit using parameters: <span class="subst">$&#123;model2.parent.extractParamMap&#125;</span>"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 构建测试集</span></span><br><span class="line">    <span class="keyword">val</span> test: <span class="type">DataFrame</span> = spark.createDataFrame(<span class="type">Seq</span>(</span><br><span class="line">      (<span class="number">1.0</span>, <span class="type">Vectors</span>.dense(<span class="number">-1.0</span>, <span class="number">1.5</span>, <span class="number">1.3</span>)),</span><br><span class="line">      (<span class="number">0.0</span>, <span class="type">Vectors</span>.dense(<span class="number">3.0</span>, <span class="number">2.0</span>, <span class="number">-0.1</span>)),</span><br><span class="line">      (<span class="number">1.0</span>, <span class="type">Vectors</span>.dense(<span class="number">0.0</span>, <span class="number">2.2</span>, <span class="number">-1.5</span>))</span><br><span class="line">    )).toDF(<span class="string">"label"</span>, <span class="string">"features"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 预测的时候仅仅使用'features'列</span></span><br><span class="line">    <span class="keyword">val</span> res: <span class="type">Array</span>[<span class="type">Row</span>] = model2.transform(test)</span><br><span class="line">      .select(<span class="string">"features"</span>, <span class="string">"label"</span>, <span class="string">"myProbability"</span>, <span class="string">"prediction"</span>)</span><br><span class="line">      .collect()</span><br><span class="line"></span><br><span class="line">    res.foreach &#123; <span class="keyword">case</span> <span class="type">Row</span>(features: <span class="type">Vector</span>, label: <span class="type">Double</span>, prob: <span class="type">Vector</span>, prediction: <span class="type">Double</span>) =&gt;</span><br><span class="line">        println(<span class="string">s"(<span class="subst">$features</span>, <span class="subst">$label</span>) -&gt; prob=<span class="subst">$prob</span>, prediction=<span class="subst">$prediction</span>"</span>)</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h1 id="Pipeline"><a href="#Pipeline" class="headerlink" title="Pipeline"></a>Pipeline</h1><figure class="highlight scala"><table><tr><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 1. Pipeline是由一系列的PipelineStages构成，其中每个stage要么是Transformer，要么是Estimator</span></span><br><span class="line"><span class="comment"> * 2. 输入DataFrame进入Pipeline后按照顺序被传给每个stage，在transformer stage中，transform()方法被调用在DataFrame，</span></span><br><span class="line"><span class="comment"> *    在Estimator的stage中，fit()方法被调用产生transformer，并称之为PipelineModel</span></span><br><span class="line"><span class="comment"> * 3. Pipeline是一个Estimator，在执行fit()之后产生PipelineModel并用在预测环节，PipelineModel和初始的Pipeline有相同数量的stage,</span></span><br><span class="line"><span class="comment"> *    但初始的Pipeline中的所有Estimators在PipelineModel中都被转成了Transformer</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">object</span> <span class="title">Pipeline</span> </span>&#123;</span><br><span class="line">  <span class="function"><span class="keyword">def</span> <span class="title">main</span></span>(args: <span class="type">Array</span>[<span class="type">String</span>]): <span class="type">Unit</span> = &#123;</span><br><span class="line">    <span class="keyword">val</span> spark: <span class="type">SparkSession</span> = <span class="type">SparkSession</span>.builder().appName(<span class="string">"Pipeline"</span>).master(<span class="string">"local"</span>).getOrCreate()</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 用id,text以及label的tuple构成的Sequence作为训练documents</span></span><br><span class="line">    <span class="keyword">val</span> training: <span class="type">DataFrame</span> = spark.createDataFrame(<span class="type">Seq</span>(</span><br><span class="line">      (<span class="number">0</span>L, <span class="string">"a b c d e spark"</span>, <span class="number">1.0</span>),</span><br><span class="line">      (<span class="number">1</span>L, <span class="string">"b d"</span>, <span class="number">0.0</span>),</span><br><span class="line">      (<span class="number">2</span>L, <span class="string">"spark f g h"</span>, <span class="number">1.0</span>),</span><br><span class="line">      (<span class="number">3</span>L, <span class="string">"hadoop mapreduce"</span>, <span class="number">0.0</span>)</span><br><span class="line">    )).toDF(<span class="string">"id"</span>, <span class="string">"text"</span>, <span class="string">"label"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 构建由tokenizer, hashingTF, and lr构成的pipeline，</span></span><br><span class="line">    <span class="keyword">val</span> tokenizer: <span class="type">Tokenizer</span> = <span class="keyword">new</span> <span class="type">Tokenizer</span>()</span><br><span class="line">      .setInputCol(<span class="string">"text"</span>)</span><br><span class="line">      .setOutputCol(<span class="string">"words"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// setBinary:</span></span><br><span class="line">    <span class="comment">//    true(伯努利计算，默认), 统计某词在一篇文章中只要出现了就为1，否则为0</span></span><br><span class="line">    <span class="comment">//    false(多项式分布计算)，一个词在一篇文章中出现多少次，计算多少次</span></span><br><span class="line">    <span class="comment">// setNumFeatures: 设计词表的大小</span></span><br><span class="line">    <span class="comment">// HashingTF将文档的每行转换成(词表大小, 词的id&lt;单个字符时同ascii码一样&gt;, 词频)形式，其中词频指的是当前行(文章的词频)</span></span><br><span class="line">    <span class="keyword">val</span> hashingTF: <span class="type">HashingTF</span> = <span class="keyword">new</span> <span class="type">HashingTF</span>()</span><br><span class="line">      .setBinary(<span class="literal">true</span>)</span><br><span class="line">      .setNumFeatures(<span class="number">1000</span>)</span><br><span class="line">      .setInputCol(tokenizer.getOutputCol)</span><br><span class="line">      .setOutputCol(<span class="string">"features"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> lr: <span class="type">LogisticRegression</span> = <span class="keyword">new</span> <span class="type">LogisticRegression</span>()</span><br><span class="line">      .setMaxIter(<span class="number">10</span>)</span><br><span class="line">      .setRegParam(<span class="number">0.001</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> pipeline: <span class="type">Pipeline</span> = <span class="keyword">new</span> <span class="type">Pipeline</span>()</span><br><span class="line">      .setStages(<span class="type">Array</span>(tokenizer, hashingTF, lr))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> model: <span class="type">PipelineModel</span> = pipeline.fit(training)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将拟合的模型保存(Transformer)</span></span><br><span class="line">    model.write.overwrite().save(<span class="string">"/Users/bytedance/ByteCode/SparkLab/data/spark-logistic-regression-model"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 将未拟合的模型保存(Estimator)</span></span><br><span class="line">    pipeline.write.overwrite().save(<span class="string">"/Users/bytedance/ByteCode/SparkLab/data/unfit-lr-model"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 加载保存的模型</span></span><br><span class="line">    <span class="keyword">val</span> sameModel: <span class="type">PipelineModel</span> = <span class="type">PipelineModel</span>.load(<span class="string">"/Users/bytedance/ByteCode/SparkLab/data/spark-logistic-regression-model"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">// 用id, text但是没有label的tuple构成的Sequence作为测试documents</span></span><br><span class="line">    <span class="keyword">val</span> test: <span class="type">DataFrame</span> = spark.createDataFrame(<span class="type">Seq</span>(</span><br><span class="line">      (<span class="number">4</span>L, <span class="string">"spark i j k"</span>),</span><br><span class="line">      (<span class="number">5</span>L, <span class="string">"l m n"</span>),</span><br><span class="line">      (<span class="number">6</span>L, <span class="string">"spark hadoop spark"</span>),</span><br><span class="line">      (<span class="number">7</span>L, <span class="string">"apache hadoop"</span>)</span><br><span class="line">    )).toDF(<span class="string">"id"</span>, <span class="string">"text"</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">val</span> res: <span class="type">Array</span>[<span class="type">Row</span>] = sameModel.transform(test)</span><br><span class="line">      .select(<span class="string">"id"</span>, <span class="string">"text"</span>, <span class="string">"probability"</span>, <span class="string">"prediction"</span>)</span><br><span class="line">      .collect()</span><br><span class="line"></span><br><span class="line">      res.foreach &#123; <span class="keyword">case</span> <span class="type">Row</span>(id: <span class="type">Long</span>, text: <span class="type">String</span>, prob: <span class="type">Vector</span>, prediction: <span class="type">Double</span>) =&gt;</span><br><span class="line">        println(<span class="string">s"(<span class="subst">$id</span>, <span class="subst">$text</span>) --&gt; prob=<span class="subst">$prob</span>, prediction=<span class="subst">$prediction</span>"</span>)</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
    </div>

    
    
    

      <footer class="post-footer">

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2020/08/16/Postman%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="prev" title="PostMan学习笔记">
      <i class="fa fa-chevron-left"></i> PostMan学习笔记
    </a></div>
      <div class="post-nav-item">
    <a href="/2020/09/05/Python%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" rel="next" title="Python学习笔记">
      Python学习笔记 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  

  </div>


          </div>
          
    
  <div class="comments">
    <div id="lv-container" data-id="city" data-uid="MTAyMC81MDU4NS8yNzA2OA=="></div>
  </div>
  

<script>
  window.addEventListener('tabs:register', () => {
    let activeClass = CONFIG.comments.activeClass;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">


      <!-- Insert clustrmaps.com -->
      <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=KtGJoKXxclcQVx7sNXJH54c78A8tjanQrniTrGne0CE&cl=ffffff&w=a"></script>

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#基本统计量"><span class="nav-number">1.</span> <span class="nav-text">基本统计量</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#基本组件"><span class="nav-number">2.</span> <span class="nav-text">基本组件</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Pipeline"><span class="nav-number">3.</span> <span class="nav-text">Pipeline</span></a></li></ol></div>
      </div>
      <!--/noindex-->



      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="黄宁"
      src="/images/%E4%BA%91%E5%8D%97%E5%B1%B1%E9%97%B4%E8%87%AA%E6%8B%8D.jpg">
  <p class="site-author-name" itemprop="name">黄宁</p>
  <div class="site-description" itemprop="description">务实敢为 追求极致</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives">
          <span class="site-state-item-count">17</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">23</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/HuangNing616" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;HuangNing616" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:nnkawayi@qq.com" title="E-Mail → mailto:nnkawayi@qq.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
  </div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">黄宁</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    <span title="站点总字数">130k</span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    <span title="站点阅读时长">1:58</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        访客数：<span id="busuanzi_value_site_uv"></span>人
      </span>
    </span>
    <span class="post-meta-divider">|</span>
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        总访问量：<span id="busuanzi_value_site_pv"></span>次
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="//cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script>
  <script src="//cdn.jsdelivr.net/gh/fancyapps/fancybox@3/dist/jquery.fancybox.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  
  <script>
    (function(){
      var bp = document.createElement('script');
      var curProtocol = window.location.protocol.split(':')[0];
      bp.src = (curProtocol === 'https') ? 'https://zz.bdstatic.com/linksubmit/push.js' : 'http://push.zhanzhang.baidu.com/push.js';
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(bp, s);
    })();
  </script>















  

  

  

<script>
NexT.utils.loadComments(document.querySelector('#lv-container'), () => {
  window.livereOptions = {
    refer: location.pathname.replace(CONFIG.root, '').replace('index.html', '')
  };
  (function(d, s) {
    var j, e = d.getElementsByTagName(s)[0];
    if (typeof LivereTower === 'function') { return; }
    j = d.createElement(s);
    j.src = 'https://cdn-city.livere.com/js/embed.dist.js';
    j.async = true;
    e.parentNode.insertBefore(j, e);
  })(document, 'script');
});
</script>


  <div id="tp-weather-widget"></div>
  <script>
    (function(a,h,g,f,e,d,c,b){b=function(){d=h.createElement(g);c=h.getElementsByTagName(g)[0];d.src=e;d.charset="utf-8";d.async=1;c.parentNode.insertBefore(d,c)};a["SeniverseWeatherWidgetObject"]=f;a[f]||(a[f]=function(){(a[f].q=a[f].q||[]).push(arguments)});a[f].l=+new Date();if(a.attachEvent){a.attachEvent("onload",b)}else{a.addEventListener("load",b,false)}}(window,document,"script","SeniverseWeatherWidget","//cdn.sencdn.com/widget2/static/js/bundle.js?t="+parseInt((new Date().getTime() / 100000000).toString(),10)));
    window.SeniverseWeatherWidget('show', {
      flavor: "bubble",
      location: "WX4FBXXFKE4F",
      geolocation: false,
      language: "zh-Hans",
      unit: "c",
      theme: "auto",
      token: "64e9ee0f-b930-45d8-8184-36671cb034af",
      hover: "enabled",
      container: "tp-weather-widget"
    })
  </script>
  
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/koharu.model.json"},"display":{"position":"right","width":200,"height":400},"mobile":{"show":true},"react":{"opacity":0.7}});</script></body>
</html>
